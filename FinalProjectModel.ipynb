{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.03866353588264538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(12, 8))\\nplt.scatter(X_test['year'], np.expm1(y_test), label='Actual Points', alpha=0.7)\\nplt.scatter(X_test['year'], np.expm1(y_pred), label='Predicted Points', alpha=0.7)\\nplt.title('Actual vs Predicted Points Over Time')\\nplt.xlabel('Year')\\nplt.ylabel('Points')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "constructor_results = pd.read_csv('constructor_results.csv')\n",
    "df = pd.DataFrame(constructor_results)\n",
    "constructor_standings = pd.read_csv('constructor_standings.csv')\n",
    "constructors = pd.read_csv('constructors.csv')\n",
    "races = pd.read_csv('races.csv')\n",
    "results = pd.read_csv('results.csv')\n",
    "\n",
    "df = pd.merge(constructor_results, results, on=['raceId', 'constructorId'], suffixes=('_constructor', '_results'))\n",
    "df = pd.merge(df, races, on='raceId')\n",
    "df = pd.merge(df, constructors, on='constructorId')\n",
    "df = pd.merge(df, constructor_standings, on=['raceId', 'constructorId'], suffixes=('_constructor', '_standings'))\n",
    "#print(df.head())\n",
    "#print(df.describe())\n",
    "#changing the model's dataset to only include data between the years 1961 and 1990\n",
    "df = df[(df['year'] >= 1961) & (df['year'] <= 1990)]\n",
    "\n",
    "#desired features for the model's dataset\n",
    "selected_columns = [\n",
    "    'grid', 'laps',  \n",
    "    'position_constructor',   \n",
    "    'year', 'round', 'circuitId', 'points', 'position_standings', 'wins'  \n",
    "]\n",
    "\n",
    "#model only has desired features\n",
    "df = df[selected_columns]\n",
    "\n",
    "#converting categorical columns into numerical columns\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "#dropping all rows where at least 1 element is missing\n",
    "#df = df.dropna()\n",
    "\n",
    "#dataset of the predictor variables\n",
    "X = df.drop('points', axis=1)\n",
    "\n",
    "#series representing the target variable\n",
    "y = df['points']\n",
    "\n",
    "#evening the distribution of values of the predictor variable\n",
    "y= np.log1p(y)\n",
    "\n",
    "#range of hyperparameters to test on the model\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],       # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],      # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],     # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]        # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "#machine learning model object\n",
    "model = RandomForestRegressor(n_estimators = 100, max_depth = 20, min_samples_leaf = 1, min_samples_split = 2, random_state = 42)\n",
    "\n",
    "\"\"\"\n",
    "I did include fitting the model without grid search CV and with grid search CV.\n",
    "Fitting with grid search CV are currently comments\n",
    "\"\"\"\n",
    "\n",
    "#grid search CV object\n",
    "#grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "#training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "#fitting the training data to the model \n",
    "#grid_search.fit(X_train, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#best possible combination of hyperparameters for the model\n",
    "#best_params = grid_search.best_params_\n",
    "\n",
    "#model that performed the best during hyperparameter tuning\n",
    "#best_estimator = grid_search.best_estimator_\n",
    "\n",
    "#predicted values\n",
    "#y_pred = grid_search.predict(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#efficiency of model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "#importance of each feature in dataset when making predictions\n",
    "#importance_of_features = model.feature_importances_\n",
    "\n",
    "#predictor variables\n",
    "#X_columns = X.columns\n",
    "\n",
    "#list paring predictor variable name with its importance to making predictions\n",
    "#importance_pairs = list(zip(importance_of_features, X_columns))\n",
    "\n",
    "#sorted list of predictor variables in order of importance to making predicitions\n",
    "#sorted_important_pairs = sorted(importance_pairs, key = lambda x:x[0], reverse = True)\n",
    "\n",
    "\"\"\"\n",
    "loops through all variables in sorted_imported_pairs in order to print\n",
    "the variable name with its corresponding importance to making predicitons\n",
    "\"\"\"\n",
    "#for importance, variable in sorted_important_pairs:\n",
    "    #print(f\"{variable}: {importance}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "scatter plot to compare all actual points to their corresponding\n",
    "predicted points between the years of 1961 and 1990\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X_test['year'], np.expm1(y_test), label='Actual Points', alpha=0.7)\n",
    "plt.scatter(X_test['year'], np.expm1(y_pred), label='Predicted Points', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Points Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Points')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
